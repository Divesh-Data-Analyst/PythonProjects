{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dc1029f",
   "metadata": {},
   "source": [
    "# Automated Crypto Web Scrapper\n",
    "\n",
    "This is project 4 out of 5 in the Analyst Builder's Python Programming for Beginners Series. I will add my own changes and modifications compared to the one shown in the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf07c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Make changes here for File Dir and Cryptocurrency \n",
    "URL = \"https://coinmarketcap.com/currencies/ethereum/\"\n",
    "CSV_FILE_PATH = \"/Users/username/Desktop/Python/CryptoTest/Crypto_Automated_Pull.csv\"\n",
    "\n",
    "def automated_crypto_pull():\n",
    "    try:\n",
    "        page = requests.get(URL)\n",
    "        page.raise_for_status()  \n",
    "        \n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "        \n",
    "        # Make changes within the elements if tracking a different Cryptocurency\n",
    "        crypto_name_elem = soup.find(\"span\", class_=\"sc-f70bb44c-0 jltoa\")\n",
    "        crypto_price_elem = soup.find(\"span\", class_=\"sc-f70bb44c-0 jxpCgO base-text\")\n",
    "        \n",
    "        if crypto_name_elem and crypto_price_elem:\n",
    "            crypto_name = crypto_name_elem.text\n",
    "            crypto_price = crypto_price_elem.text.replace(\"$\", \"\")\n",
    "            \n",
    "            date_time = datetime.now()\n",
    "            \n",
    "            data_dict = {\n",
    "                \"Crypto Name\": crypto_name,\n",
    "                \"Crypto Price\": crypto_price,\n",
    "                \"Time Pulled\": date_time\n",
    "            }\n",
    "            \n",
    "            df = pd.DataFrame([data_dict])\n",
    "            \n",
    "            # Write to CSV file\n",
    "            mode = \"a\" if os.path.exists(CSV_FILE_PATH) else \"w\"\n",
    "            with open(CSV_FILE_PATH, mode, newline=\"\") as csv_file:\n",
    "                df.to_csv(csv_file, index=False, header=(mode == \"w\"))\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error during request: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    automated_crypto_pull()\n",
    "    time.sleep(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16769a8",
   "metadata": {},
   "source": [
    "### Project Overview and Lessons Learnt \n",
    "\n",
    "I spent quite some time on this project and enjoyed working on it - I liked the various aspects that are needed in order to pull data from the web and how we can use python in order to simplify and automate the process. \n",
    "\n",
    "If you use this please ensure that you do not violate the Terms of Service of the website; ensure they have not restricted \"webscraping\". Else you will error out.\n",
    "\n",
    "I see many cases in which this method may come in handy and I am really glad I was able to create my own, in the future if I come across this I will create a way to make it more visually appealing and a price graph. I will also create a function that will 'notify' me when the price will reach a desired range."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
